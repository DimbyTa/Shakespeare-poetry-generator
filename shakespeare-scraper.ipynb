{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a955b476",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-07T23:23:13.509283Z",
     "iopub.status.busy": "2023-08-07T23:23:13.508896Z",
     "iopub.status.idle": "2023-08-07T23:23:30.262986Z",
     "shell.execute_reply": "2023-08-07T23:23:30.261996Z"
    },
    "papermill": {
     "duration": 16.760842,
     "end_time": "2023-08-07T23:23:30.266037",
     "exception": false,
     "start_time": "2023-08-07T23:23:13.505195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\r\n",
      "  Downloading Scrapy-2.10.0-py2.py3-none-any.whl (281 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting Twisted>=18.9.0 (from scrapy)\r\n",
      "  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from scrapy) (41.0.1)\r\n",
      "Collecting cssselect>=0.9.1 (from scrapy)\r\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\r\n",
      "Collecting itemloaders>=1.0.1 (from scrapy)\r\n",
      "  Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\r\n",
      "Collecting parsel>=1.5.0 (from scrapy)\r\n",
      "  Downloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\r\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from scrapy) (23.2.0)\r\n",
      "Collecting queuelib>=1.4.2 (from scrapy)\r\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\r\n",
      "Collecting service-identity>=18.1.0 (from scrapy)\r\n",
      "  Downloading service_identity-23.1.0-py3-none-any.whl (12 kB)\r\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\r\n",
      "  Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\r\n",
      "Collecting zope.interface>=5.1.0 (from scrapy)\r\n",
      "  Downloading zope.interface-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting protego>=0.1.15 (from scrapy)\r\n",
      "  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\r\n",
      "Collecting itemadapter>=0.1.0 (from scrapy)\r\n",
      "  Downloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from scrapy) (59.8.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from scrapy) (21.3)\r\n",
      "Collecting tldextract (from scrapy)\r\n",
      "  Downloading tldextract-3.4.4-py3-none-any.whl (93 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from scrapy) (4.9.3)\r\n",
      "Collecting PyDispatcher>=2.0.5 (from scrapy)\r\n",
      "  Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->scrapy) (1.15.1)\r\n",
      "Requirement already satisfied: jmespath>=0.9.5 in /opt/conda/lib/python3.10/site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from protego>=0.1.15->scrapy) (1.16.0)\r\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy) (23.1.0)\r\n",
      "Requirement already satisfied: pyasn1 in /opt/conda/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\r\n",
      "Requirement already satisfied: pyasn1-modules in /opt/conda/lib/python3.10/site-packages (from service-identity>=18.1.0->scrapy) (0.2.7)\r\n",
      "Collecting constantly>=15.1 (from Twisted>=18.9.0->scrapy)\r\n",
      "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\r\n",
      "Collecting incremental>=21.3.0 (from Twisted>=18.9.0->scrapy)\r\n",
      "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\r\n",
      "Collecting Automat>=0.8.0 (from Twisted>=18.9.0->scrapy)\r\n",
      "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\r\n",
      "Collecting hyperlink>=17.1.1 (from Twisted>=18.9.0->scrapy)\r\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /opt/conda/lib/python3.10/site-packages (from Twisted>=18.9.0->scrapy) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->scrapy) (3.0.9)\r\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from tldextract->scrapy) (3.4)\r\n",
      "Requirement already satisfied: requests>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from tldextract->scrapy) (2.31.0)\r\n",
      "Collecting requests-file>=1.4 (from tldextract->scrapy)\r\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\r\n",
      "Requirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.10/site-packages (from tldextract->scrapy) (3.12.2)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (3.1.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.1.0->tldextract->scrapy) (2023.5.7)\r\n",
      "Installing collected packages: PyDispatcher, incremental, constantly, zope.interface, w3lib, queuelib, protego, itemadapter, hyperlink, cssselect, Automat, Twisted, requests-file, parsel, tldextract, service-identity, itemloaders, scrapy\r\n",
      "Successfully installed Automat-22.10.0 PyDispatcher-2.0.7 Twisted-22.10.0 constantly-15.1.0 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.8.0 itemloaders-1.1.0 parsel-1.8.1 protego-0.2.1 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.10.0 service-identity-23.1.0 tldextract-3.4.4 w3lib-2.1.2 zope.interface-6.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f440e9fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T23:23:30.276906Z",
     "iopub.status.busy": "2023-08-07T23:23:30.276068Z",
     "iopub.status.idle": "2023-08-07T23:23:30.987662Z",
     "shell.execute_reply": "2023-08-07T23:23:30.986357Z"
    },
    "papermill": {
     "duration": 0.719342,
     "end_time": "2023-08-07T23:23:30.990025",
     "exception": false,
     "start_time": "2023-08-07T23:23:30.270683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa57d41e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T23:23:31.000955Z",
     "iopub.status.busy": "2023-08-07T23:23:30.999996Z",
     "iopub.status.idle": "2023-08-07T23:23:31.011939Z",
     "shell.execute_reply": "2023-08-07T23:23:31.010798Z"
    },
    "papermill": {
     "duration": 0.019625,
     "end_time": "2023-08-07T23:23:31.014328",
     "exception": false,
     "start_time": "2023-08-07T23:23:30.994703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShakespeareSpider(scrapy.Spider):\n",
    "    \"\"\"\n",
    "    Spider for the website: https://allpoetry.com\n",
    "    Scraping only the most famous poems\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        #super(ShakespeareSpider, self).__init__()\n",
    "        self.name = \"Poems\"\n",
    "        self.start_urls = ['https://allpoetry.com']\n",
    "        self.base_url = 'https://allpoetry.com'\n",
    "        self.poems = []\n",
    "        self.counter = 0\n",
    "    def start_requests(self):\n",
    "        page1 = 'https://allpoetry.com/William-Shakespeare'\n",
    "        yield scrapy.Request(page1,callback=self.parse_page, headers={'User-Agent': \n",
    "                            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:54.0) Gecko/20100101 Firefox/54.0'\n",
    "                            })\n",
    "        \n",
    "    def parse_page(self,response):\n",
    "        \"\"\"\n",
    "        Processing each page of the website\n",
    "        \"\"\"\n",
    "        \n",
    "        poems_list_page = response.css('div.author_link_list')\n",
    "        for items in poems_list_page:\n",
    "\n",
    "            links = items.css('a')\n",
    "            for link in links:\n",
    "                if self.counter >= 0 and self.counter < 49:\n",
    "                    poem = dict()\n",
    "                    title = link.xpath('text()').get()\n",
    "                    href = link.xpath('@href').get()\n",
    "                    poem['title'] = title\n",
    "                    print(title)\n",
    "                    #\n",
    "                    if href:\n",
    "                        if \"Full title\" not in title:\n",
    "                            yield scrapy.Request(self.base_url+href, callback=self.parse_poem,cb_kwargs={'poem': poem})\n",
    "        \n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "    def parse_poem(self,response,poem):\n",
    "        \"\"\"\n",
    "        getting the body of the poem\n",
    "        \"\"\"\n",
    "        if len(self.poems) > 47:\n",
    "            #assert len(self.poems) > 0\n",
    "            df = pd.DataFrame.from_dict(self.poems)\n",
    "            print(\"printing DataFrame\")\n",
    "            print(df.head())\n",
    "            df.to_csv('Shakespeare_poems.csv')\n",
    "        else:\n",
    "            poem_body = response.css('div.poem_body')\n",
    "            text = poem_body.xpath('./div[2]//p//text()').extract()\n",
    "            if len(text) == 0:\n",
    "                text = poem_body.xpath('./div[2]//text()').extract()\n",
    "            poem['poem_body'] = text\n",
    "            print(poem.keys())\n",
    "            self.poems.append(poem)\n",
    "            self.counter += 1\n",
    "            print(len(self.poems))\n",
    "\n",
    "    #print(self.poems)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bff6d17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T23:23:31.024602Z",
     "iopub.status.busy": "2023-08-07T23:23:31.024287Z",
     "iopub.status.idle": "2023-08-07T23:28:26.306372Z",
     "shell.execute_reply": "2023-08-07T23:28:26.305067Z"
    },
    "papermill": {
     "duration": 295.28986,
     "end_time": "2023-08-07T23:28:26.308735",
     "exception": false,
     "start_time": "2023-08-07T23:23:31.018875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:23:31 [scrapy.utils.log] INFO: Scrapy 2.10.0 started (bot: scrapybot)\n",
      "2023-08-07 23:23:31 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0], pyOpenSSL 23.2.0 (OpenSSL 3.1.1 30 May 2023), cryptography 41.0.1, Platform Linux-5.15.120+-x86_64-with-glibc2.31\n",
      "2023-08-07 23:23:31 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2023-08-07 23:23:31 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'DOWNLOAD_DELAY': 5,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:54.0) '\n",
      "               'Gecko/20100101 Firefox/54.0'}\n",
      "2023-08-07 23:23:31 [py.warnings] WARNING: /opt/conda/lib/python3.10/site-packages/scrapy/utils/request.py:248: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-08-07 23:23:31 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2023-08-07 23:23:31 [scrapy.extensions.telnet] INFO: Telnet Password: ee1ffdbb43fabf40\n",
      "2023-08-07 23:23:31 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2023-08-07 23:23:31 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-08-07 23:23:31 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-08-07 23:23:31 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-08-07 23:23:31 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-08-07 23:23:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-08-07 23:23:31 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2023-08-07 23:23:32 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): publicsuffix.org:443\n",
      "2023-08-07 23:23:32 [urllib3.connectionpool] DEBUG: https://publicsuffix.org:443 \"GET /list/public_suffix_list.dat HTTP/1.1\" 200 74694\n",
      "2023-08-07 23:23:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/William-Shakespeare> (referer: None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Lover's Complaint\n",
      "A Madrigal\n",
      "All The World's A Stage\n",
      "Aubade\n",
      "Blow, Blow, Thou Winter Wind\n",
      "Bridal Song\n",
      "Carpe Diem\n",
      "Dear Friend\n",
      "Dirge\n",
      "Dirge Of The Three Queens\n",
      "Fairy Land I\n",
      "Fairy Land II\n",
      "Fairy Land III\n",
      "Fairy Land IV\n",
      "Fairy Land V\n",
      "Fear No More\n",
      "Fidele\n",
      "Friends, Romans, countrymen, lend me your ears\n",
      "From The Rape Of Lucrece\n",
      "From Venus And Adonis\n",
      "Helen's Soliloqy (All's Well That Ends Well)\n",
      "How Like A Winter Hath My Absence Been\n",
      "It Was A Lover And His Lass\n",
      "Juliet's Soliloquy\n",
      "Love\n",
      "Macbeth - Three witches casting a spell\n",
      "Now The Hungry Lion Roars\n",
      "Now, my co-mates and brothers in exile\n",
      "O Never Say That I Was False of Heart\n",
      "Orpheus With His Lute Made Trees\n",
      "Sigh No More\n",
      "Silvia\n",
      "Sir, in my heart there was a kind of fighting (Hamlet Act V, Scene II)\n",
      "Some Say That Ever ‘Gainst That Season Comes (Hamlet, Act I, Scene I)\n",
      "Song of the Witches: Double, double toil and trouble\n",
      "Sonnet 100: \"Where art thou Muse that thou forget'st so long,...\"\n",
      "Sonnet 101: \"O truant Muse what shall be thy amends...\"\n",
      "Sonnet 102: \"My love is strengthened, though more weak in seeming;...\"\n",
      "Sonnet 103: \"Alack! what poverty my Muse brings forth,...\"\n",
      "Sonnet 104: \"To me, fair friend, you never can be old,...\"\n",
      "Sonnet 105: \"Let not my love be called idolatry,...\"\n",
      "Sonnet 106: \"When in the chronicle of wasted time...\"\n",
      "Sonnet 107: \"Not mine own fears, nor the prophetic soul...\"\n",
      "Sonnet 108: \"What's in the brain, that ink may character,...\"\n",
      "Sonnet 109: \"O! never say that I was false of heart,...\"\n",
      "Sonnet 10: “For shame deny that thou bear'st love to any…”\n",
      "Sonnet 110: \"Alas, 'tis true I have gone here and there...\"\n",
      "Sonnet 111: \"O, for my sake do you with Fortune chide...\"\n",
      "Sonnet 112: \"Your love and pity doth the impression fill,...\"\n",
      "Full title list →\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:23:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/8449711-Dirge-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:23:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/16377694-Dear-Friend-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:23:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/8449731-Carpe-Diem-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Bridal-Song> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Blow,-Blow,-Thou-Winter-Wind> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:24:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Aubade> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/All-The-World's-A-Stage> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:24:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/A-Madrigal> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:24:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/A-Lover's-Complaint> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:24:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/16845019-Sir--in-my-heart-there-was-a-kind-of-fighting--Hamlet-Act-V--Scen-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:24:31 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 11 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-08-07 23:24:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/8449479-Silvia-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:24:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sigh-No-More> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:24:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Orpheus-With-His-Lute-Made-Trees> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:24:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/O-Never-Say-That-I-Was-False-of-Heart> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:24:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Now,-my-co-mates-and-brothers-in-exile> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:25:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/14326605-Now-The-Hungry-Lion-Roars-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:25:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-112:--Your-love-and-pity-doth-the-impression-fill,...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:25:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-111:--O,-for-my-sake-do-you-with-Fortune-chide...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:25:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-110:--Alas,-'tis-true-I-have-gone-here-and-there...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:25:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-10:-For-shame-deny-that-thou-bear'st-love-to-any> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:25:31 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 10 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-08-07 23:25:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-109:--O!-never-say-that-I-was-false-of-heart,...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:25:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-108:--What's-in-the-brain,-that-ink-may-character,...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:25:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-107:--Not-mine-own-fears,-nor-the-prophetic-soul...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:25:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-106:--When-in-the-chronicle-of-wasted-time...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:25:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-105:--Let-not-my-love-be-called-idolatry,...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:26:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-104:--To-me,-fair-friend,-you-never-can-be-old,...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:26:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-103:--Alack!-what-poverty-my-Muse-brings-forth,...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:26:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-102:--My-love-is-strengthened,-though-more-weak-in-seeming;...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:26:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-101:--O-truant-Muse-what-shall-be-thy-amends...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:26:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Sonnet-100:--Where-art-thou-Muse-that-thou-forget'st-so-long,...-> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:26:31 [scrapy.extensions.logstats] INFO: Crawled 31 pages (at 10 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-08-07 23:26:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/14326598-Song-of-the-Witches--Double--double-toil-and-trouble-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:26:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/14326600-Some-Say-That-Ever--Gainst-That-Season-Comes--Hamlet--Act-I--Scen-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:26:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/14326604-Macbeth---Three-witches-casting-a-spell-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:26:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/14326610-Love-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:26:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Juliet's-Soliloquy> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:27:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/It-Was-A-Lover-And-His-Lass> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:27:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/How-Like-A-Winter-Hath-My-Absence-Been> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:27:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/14326606-Helen-s-Soliloqy--All-s-Well-That-Ends-Well--by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:27:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/14326609-From-Venus-And-Adonis-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:27:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/14326602-From-The-Rape-Of-Lucrece-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:27:31 [scrapy.extensions.logstats] INFO: Crawled 41 pages (at 10 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-08-07 23:27:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/poem/14326601-Friends--Romans--countrymen--lend-me-your-ears-by-William-Shakespeare> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:27:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Fidele> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:27:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Fear-No-More> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:27:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Fairy-Land-V> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:27:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Fairy-Land-IV> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:28:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Fairy-Land-III> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:28:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Fairy-Land-II> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:28:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Fairy-Land-I> (referer: https://allpoetry.com/William-Shakespeare)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['title', 'poem_body'])\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 23:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://allpoetry.com/Dirge-Of-The-Three-Queens> (referer: https://allpoetry.com/William-Shakespeare)\n",
      "2023-08-07 23:28:26 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2023-08-07 23:28:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 44073,\n",
      " 'downloader/request_count': 50,\n",
      " 'downloader/request_method_count/GET': 50,\n",
      " 'downloader/response_bytes': 634782,\n",
      " 'downloader/response_count': 50,\n",
      " 'downloader/response_status_count/200': 50,\n",
      " 'elapsed_time_seconds': 294.97617,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2023, 8, 7, 23, 28, 26, 219306),\n",
      " 'httpcompression/response_bytes': 2002775,\n",
      " 'httpcompression/response_count': 50,\n",
      " 'log_count/DEBUG': 53,\n",
      " 'log_count/INFO': 14,\n",
      " 'log_count/WARNING': 1,\n",
      " 'memusage/max': 278990848,\n",
      " 'memusage/startup': 264671232,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 50,\n",
      " 'scheduler/dequeued': 50,\n",
      " 'scheduler/dequeued/memory': 50,\n",
      " 'scheduler/enqueued': 50,\n",
      " 'scheduler/enqueued/memory': 50,\n",
      " 'start_time': datetime.datetime(2023, 8, 7, 23, 23, 31, 243136)}\n",
      "2023-08-07 23:28:26 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing DataFrame\n",
      "                          title  \\\n",
      "0                         Dirge   \n",
      "1                   Dear Friend   \n",
      "2                    Carpe Diem   \n",
      "3                   Bridal Song   \n",
      "4  Blow, Blow, Thou Winter Wind   \n",
      "\n",
      "                                           poem_body  \n",
      "0  [COME away, come away, death, , \\n   And in sa...  \n",
      "1  [When to the session of sweet silent thought, ...  \n",
      "2  [O mistress mine, where are you roaming? , \\nO...  \n",
      "3  [ROSES, their sharp spines being gone, , \\nNot...  \n",
      "4  [Blow, blow, thou winter wind , \\nThou art not...  \n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess(settings={\n",
    "    'DOWNLOAD_DELAY': 5,\n",
    "    'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:54.0) Gecko/20100101 Firefox/54.0'\n",
    "})\n",
    "process.crawl(ShakespeareSpider)\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 321.793944,
   "end_time": "2023-08-07T23:28:27.242659",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-07T23:23:05.448715",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
